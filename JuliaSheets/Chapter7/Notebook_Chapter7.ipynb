{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#00A6D6;\">Introduction to Quantum Cryptography - Jupyter Notebooks</h1>\n",
    "<h2 style=\"color:#00A6D6;\">Chapter 7: Distributing keys</h2>\n",
    "\n",
    "Welcome to the new Julia sheet! As usual, we will ask you to use Julia to answer a few exercises. Most importantly, however, the purpose of these Julia sheets is for you to play around and build intuition by exploring and calculating things we do NOT ask you :-) We hope that you take advantage of using Julia this way.\n",
    "\n",
    "In this Julia Jupyter notebook, we focus on getting more closely acquainted with doing error-correction!\n",
    "\n",
    "* <a href=\"#Enc\">Encoder</a>\n",
    "* <a href=\"#Dec\">Decoder</a>\n",
    "* <a href=\"#All\">Putting all together</a>\n",
    "\n",
    "The include command that follows will include all the functions that you have used on the previous weeks including D for trace distance and minEntropy for computing the min-entropy. Please use them as you see fit to answer the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\swehner\\.julia\\environments\\v1.9\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\swehner\\.julia\\environments\\v1.9\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\swehner\\.julia\\environments\\v1.9\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\swehner\\.julia\\environments\\v1.9\\Manifest.toml`\n"
     ]
    },
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {
      "application/vnd.webio.node+json": {
       "kernelId": "7fabc35d-8d75-462a-9f6d-dcc53de854fa"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"source/main.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sheet we will implement a toy information reconciliation from scratch. It will be very similar to the scheme described in the book except that we will use different codes. Let us first recall the communication scenario of a one-way information reconciliation protocol: \n",
    "\n",
    "<img src=\"source/oneway.png\">\n",
    "\n",
    "Alice holds a string $X_A$, Bob holds a string $X_B=X_A+S$ and we call $S$ the error vector. In order to help Bob recover $X_A$, Alice will encode her string in $C_A=\\textrm{Enc}(X_A)$ and send $C_A$ to Bob via a public authentic channel. Bob will input $C_A$ and $X_B$ into a decoder that will produce an estimate of Alice's string $\\hat X_A=\\textrm{Dec}(C_A,X_B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=Enc></a>\n",
    "<h2 style=\"color:#00A6D6;\">Encoder</h2>\n",
    "\n",
    "Let us first take a look at the encoder function. Given some parity check matrix $H$, the encoder function that we will use will encode $X_A$ into the syndrome of $X_A.$ That is: $C_A=H\\cdot X_A^T$. \n",
    "\n",
    "So, let us write the encoding function which is simply a small function for computing syndromes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getSyndrome (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getSyndrome(H,v)\n",
    "    # Input:\n",
    "    # ------\n",
    "    # H - k x n parity check matrix\n",
    "    # v - length n vector as a column \n",
    "    #\n",
    "    # Output:\n",
    "    # -------\n",
    "    # syn syndrome of v with parity check matrix H as row vector\n",
    "    syn = (H * v) .% 2\n",
    "    return syn\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#00A6D6;\"> Exercise 1</h3>\n",
    "\n",
    "Consider the parity check matrices corresponding to some well known codes (Golay and a Hamming Code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Golay = [1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0;\n",
    " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0;\n",
    " 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0;\n",
    " 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0;\n",
    " 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0;\n",
    " 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0;\n",
    " 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0;\n",
    " 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0;\n",
    " 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0;\n",
    " 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0;\n",
    " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1];\n",
    "\n",
    "H_Hamming = [1 0 1 0 1 0 1;\n",
    "             0 1 1 0 0 1 1;\n",
    "             0 0 0 1 1 1 1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us investigate the codes induced by these matrices:\n",
    "\n",
    "* How many different syndromes has the Hamming code?\n",
    "* How many different syndromes has the Golay code?\n",
    "\n",
    "Recall that the weight of a vector is the number of non-zero entries in the vector. Let $V_n^w$ be the set of binary vectors of length $n$ and weight $w$:\n",
    "\n",
    "* What is the number of elements in $V_7^0$,$V_7^1$,$V_7^2$ and $V_7^3$?\n",
    "* What is the number of elements in $V_{23}^0$,$V_{23}^1$,$V_{23}^2$ and $V_{23}^3$?\n",
    "\n",
    "Now, compute the encodings of the following strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = [1 0 1 1 0 1 1]'; # with the Hamming parity check matrix, as a column vector\n",
    "v1 = [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0]'; # with the Golay parity check matrix\n",
    "\n",
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=Dec></a>\n",
    "<h2 style=\"color:#00A6D6;\">Decoder</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a look at the decoder. The protocol known as syndrome decoding works as follows: \n",
    "* Alice computes the syndrome $C_A = H \\cdot X_A^T$. \n",
    "* Bob computes the syndrome $C_B=H\\cdot X_B^T$ of his string $X_B$.\n",
    "* The sum of $C_A$ and $C_B$ is fed into an estimator module that will output an estimate of the error string $\\hat S$.\n",
    "* The decoder outputs $\\hat{X}_A= X_B+\\hat S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"source/decoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gave two parity check matrices in Exercise 1: $H_{\\textrm{Hamming}}$ and $H_{\\textrm{Golay}}$. They induce a unique encoder. However, there are many possible decoders that we could associate with them. If we look at the estimator module, it takes a syndrome and outputs an error estimate. We can choose the map between syndrome and outputs of the estimator module in many different ways. \n",
    "\n",
    "We are going to implement the following estimator map for the Hamming code:\n",
    "* The zero syndrome gets mapped to the zero error string\n",
    "* For each vector $v\\in V^1_7$ compute the syndrome $s=H_{\\textrm{Hamming}}\\cdot v$ and assign the syndrome $s$ the error string $v$.\n",
    "\n",
    "We have implemented this functionality as a Julia dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Hamming = Dict()\n",
    "z = 0*eVecInt(7,1)\n",
    "s = 0*eVecInt(3,1)\n",
    "dict_Hamming[s] = z\n",
    "for i=1:7\n",
    "    vi = eVecInt(7,i)\n",
    "    s = getSyndrome(H_Hamming,vi)\n",
    "    dict_Hamming[s] = vi\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to know the output of the estimator for some concrete syndrome we would use the dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7Ã—1 Matrix{Int64}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [0 1 1]'\n",
    "dict_Hamming[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#00A6D6;\">Putting things together for the Hamming code </h2>\n",
    "\n",
    "Let's have a look at how Alice and Bob would proceed in the case of the Hamming code. How many errors - i.e. how many flipped bits - can this procedure correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice has string xA=[0; 0; 1; 0; 0; 1; 1;;]\n",
      "Alice computes syndrome cA=[0; 1; 0;;]\n",
      "Actual noise string S=[0; 0; 0; 0; 1; 0; 0;;]\n",
      "Bob receives noisy string xB=[0; 0; 1; 0; 1; 1; 1;;]\n",
      "Bob computes the syndrome cB=[1; 1; 1;;]\n",
      "Estimated noise string hatS=[0; 0; 0; 0; 1; 0; 0;;]\n",
      "Bob's output string tildeXB=[0; 0; 1; 0; 0; 1; 1;;]\n",
      "\n",
      "Bob's output equals Alice'input: true"
     ]
    }
   ],
   "source": [
    "# First, let's give a value to Alice's string xA\n",
    "xA = [0 0 1 0 0 1 1]';\n",
    "print(\"Alice has string xA=\",xA,\"\\n\")\n",
    "\n",
    "# Now Alice computes the syndrome cA and sends it to Bob\n",
    "cA = getSyndrome(H_Hamming, xA);\n",
    "print(\"Alice computes syndrome cA=\",cA,\"\\n\")\n",
    "\n",
    "# Let's suppose that Bob actually received a noise version of the string, given by a specific noise pattern\n",
    "noiseS = [0 0 0 0 1 0 0]';\n",
    "print(\"Actual noise string S=\",noiseS,\"\\n\")\n",
    "xB = xA + noiseS .% 2\n",
    "print(\"Bob receives noisy string xB=\",xB,\"\\n\")\n",
    "\n",
    "# Bob computes the syndrome of his noisy string\n",
    "cB = getSyndrome(H_Hamming, xB)\n",
    "print(\"Bob computes the syndrome cB=\",cB,\"\\n\")\n",
    "\n",
    "# Let's add up the two syndromes\n",
    "cS = (cA + cB) .% 2\n",
    "\n",
    "# An estimate of the \n",
    "estimatedS = dict_Hamming[cS]\n",
    "print(\"Estimated noise string hatS=\",estimatedS, \"\\n\")\n",
    "\n",
    "# The corrected string that Bob outputs\n",
    "tildeXB = (xB+estimatedS) .% 2\n",
    "print(\"Bob's output string tildeXB=\",tildeXB,\"\\n\\n\")\n",
    "\n",
    "# Let's check whether that is equal to Alice's original input\n",
    "print(\"Bob's output equals Alice'input: \", (tildeXB == xA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#00A6D6;\"> Exercise 2</h3>\n",
    "\n",
    "How many errors can the procedure above using the Hamming code tolerate? Investigate how many bits can be flipped above by the noise vector, and still lead to a correct decoding by Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt noise in the code above, or copy paste it here to play around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#00A6D6;\">Putting things together for the Golay code </h2>\n",
    "\n",
    "In the following exercises, let's investigate how Alice and Bob might use the Golay code in a similar fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can implement the following estimator map for the Golay code:\n",
    "\n",
    "* The zero syndrome gets mapped to the zero error string\n",
    "* For each vector $v\\in V^1_{23}$ compute the syndrome $s=H_{\\textrm{Golay}}\\cdot v$ and assign the syndrome $s$ the error string $v$.\n",
    "* For each vector $v\\in V^2_{23}$ compute the syndrome $s=H_{\\textrm{Golay}}\\cdot v$ and assign the syndrome $s$ the error string $v$.\n",
    "* For each vector $v\\in V^3_{23}$ compute the syndrome $s=H_{\\textrm{Golay}}\\cdot v$ and assign the syndrome $s$ the error string $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any}()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code codes here. You may wish to start by extending the code given for the Hamming example above.\n",
    "dict_Golay = Dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#00A6D6;\"> Exercise 3</h3>\n",
    "\n",
    "Compute the output of the estimator module of the Golay code with input error syndrome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Ã—11 Matrix{Int64}:\n",
       " 1  0  1  0  0  1  1  1  0  1  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = [1 1 1 0 0 0 0 1 1 1 0]\n",
    "s1 = [1 0 1 0 0 1 1 1 0 1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#00A6D6;\"> Exercise 4</h3>\n",
    "\n",
    "Now we can complete the decoder. Compute the output of the decoder for the Golay code with the following inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Ã—23 Matrix{Int64}:\n",
       " 0  1  0  1  1  1  0  1  1  0  0  0  1  1  1  0  0  0  1  0  1  1  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) \n",
    "\n",
    "Ca1 = [0 1 0 1 0 0 0 1 1 0 1]\n",
    "Xb1 = [0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
    "\n",
    "# 2)\n",
    "\n",
    "Ca2 = [0 0 1 0 1 1 0 1 1 1 1]\n",
    "Xb2 = [0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function decoder(Ca,Xb,estimatorDict,H)\n",
    "    # Here goes your code, you may wish to adapt the code given for the Hamming example abvove.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color:#00A6D6;\"> Exercise 5</h3>\n",
    "\n",
    "Given the following $X_A$ and $X_B$, what are the values of all the intermediate strings and what is the final decoder output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Ã—23 Matrix{Int64}:\n",
       " 0  1  1  0  1  0  0  1  1  0  0  1  1  0  0  1  0  0  1  0  1  1  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa3 = [0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0]\n",
    "Xb3 = [0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0]"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "6e49c42745a84cf789c64c46c2ff86c8",
   "lastKernelId": "7fabc35d-8d75-462a-9f6d-dcc53de854fa"
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
